{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be459417-b249-432d-ae89-771e428e17d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a6650-d5ff-45f9-8bc5-351084a9553f",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Fine-Tuning BERT</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204ce07-e830-4029-b125-949f4862490b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center>Transfer Learning en Transformers</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1860ee-1c76-4cbd-be5b-62b94dc2244a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290bf18-791d-419c-96de-698132fed544",
   "metadata": {},
   "source": [
    "### Coordinador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854f8d8-a08d-4cbb-b83e-894214e9bccb",
   "metadata": {},
   "source": [
    "- Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424139d-fa41-4141-9338-2261f8055322",
   "metadata": {},
   "source": [
    "### Conferencistas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0238b38-5ea1-474f-bb49-dcdd4e33ae3f",
   "metadata": {},
   "source": [
    "- Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "- Daniel  Montenegro, Msc, dextronomo@gmail.com \n",
    "- Oleg Jarma, Estadístico, ojarmam@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98904d-8999-45a9-96ac-77245dfb1160",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c657941-1eee-4b05-8919-9e0e61bbe8a6",
   "metadata": {},
   "source": [
    "- Maria del Pilar Montenegro, pmontenegro88@gmail.com \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62d9f5-6197-473a-b22f-e89dd23766e5",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515b1ab-445f-4e5d-a4b3-f13ebc3bf4fe",
   "metadata": {},
   "source": [
    "- Nayibe Yesenia Arias, naariasc@unal.edu.co\n",
    "- Venus Celeste Puertas, vpuertasg@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffcd2e-33ff-42db-862d-f04555a59a71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef4396-8568-4455-9cf7-54f77818da90",
   "metadata": {},
   "source": [
    "1. [How to Train BERT](https://towardsdatascience.com/how-to-train-bert-aaad00533168), James Briggs, Towards Data Science\n",
    "1. [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training), Tutoriales de HuggingFace\n",
    "1. [The untold story of GPT-3 is the transformation of OpenAI](https://bdtechtalks.com/2020/08/17/openai-gpt-3-commercial-ai/), Techtalks\n",
    "1. [OpenAI’s massive GPT-3 model is impressive, but size isn’t everything](https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/), VentureBeat\n",
    "1. [Aprendizaje Profundo-Diplomado](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Aprendizaje Profundo-PLN](https://github.com/AprendizajeProfundo/PLN)\n",
    "1. [Ashish Vaswani et al.,   Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf), diciembre 2017.\n",
    "1. [Dennis Rothman, Transformers for Natural Language processing](http://libgen.rs/search.php?req=Transformers+for+Natural+Language+processing&open=0&res=25&view=simple&phrase=1&column=def), enero 2021.\n",
    "1.[ Varios,  Dive into deep learning](https://d2l.ai/), enero 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88bbc1-2960-49b6-aed9-7d3229920c9a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d51f49-169b-4686-8bb9-076d8925647d",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Cargar Modelo Base](#Cargar-Modelo-Base)\n",
    "* [Cargar Datos](#Cargar-Datos)\n",
    "* [Dividir Datos para la tarea específica (NSP)](#Dividir-Datos-para-la-tarea-específica-(NSP))\n",
    "* [Construir Dataset que espera el modelo](#Construir-Dataset-que-espera-el-modelo)\n",
    "* [Tokenizar Frases](#Tokenizar-Frases)\n",
    "* [Construir etiquetas para la tarea MLM (Masking)](#Construir-etiquetas-para-la-tarea-MLM-(Masking))\n",
    "* [Construir Dataset y DataLoader](#Construir-Dataset-y-DataLoader)\n",
    "* [Fine-Tuning BERT](#Fine-Tuning-BERT)\n",
    "* [Fine-Tune para otras tareas (HuggingFace)](#Fine-Tune-para-otras-tareas-(HuggingFace))\n",
    "* [Fine-Tune SentenceBert](#Fine-Tune-SentenceBert)\n",
    "* [Pytorch Lightning](#Pytorch-Lightning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523205a-69fc-4de5-bf85-52c813d14111",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e46f46d-da5b-416c-a554-e806446d2d5b",
   "metadata": {},
   "source": [
    "El poder de los transformadores se deriva de la práctica común de que los modelos de transformadores sean entrenados previamente con un estándar muy alto por parte de grandes empresas como Google y OpenAI.\n",
    "\n",
    "Ahora, cuando digo preentrenado con un estándar muy alto, los costos de entrenamiento estimados de GPT-3 de OpenAI oscilan entre 4.6 y 12 millones de dólares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee59f27-bfc5-4ddb-883a-4dbabad09876",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Cargar Modelo Base</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e18322-a844-4063-ad27-526c40c8dd40",
   "metadata": {},
   "source": [
    "Comencemos llamando al modelo base junto con su tokenizador.\n",
    "\n",
    "Observe que para entrenar BERT, debemos llamar la clase *BertForPreTraining* y no *BertModel*, pues el primero se utiliza para entrenar BERT de la manera clásica (NSP y MLM).\n",
    "\n",
    "Por ejemplo, BETO (BERT en español), fue entrenado utilizando ésta técnica sobre un conjunto masivo de datos en español.\n",
    "\n",
    "Para mayor aclaración sobre el asunto, se puede consultar [BertModel or BertForPreTraining](https://stackoverflow.com/questions/66596142/bertmodel-or-bertforpretraining#:~:text=BertForPreTraining%20is%20used%20to%20train,build%20on%20top%20of%20it.), en StackOverFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00347f78-5a31-42df-8bf0-2fc9d13a59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "import torch\n",
    "\n",
    "# Tokenizador de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Modelo BERT para entrenar NSP y MLM\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814be08a-8089-4af5-a55f-ffca9f381064",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Cargar Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2791f-0e6f-415a-9d8b-da569f2d8320",
   "metadata": {},
   "source": [
    "Utilicemos un conjunto de datos sobre el que queramos entrenar BERT. Los datos utlizados en esta lección pueden ser encontrados en [jamescalam\n",
    "/\n",
    "transformers](https://github.com/jamescalam/transformers/blob/main/data/text/meditations/clean.txt).\n",
    "\n",
    "Estos textos tratan sobre 507 pasajes de meditaciones personales de James Briggs.\n",
    "\n",
    "Cada pasaje puede tener una o más frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c33a9-83bc-4893-bc61-f973f77d5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datos/clean.txt', 'r') as fp:\n",
    "    # Leer líneas del texto\n",
    "    text = fp.read().split('\\n')\n",
    "    \n",
    "# Mostrar ejemplo\n",
    "text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917f845-0c65-4089-80bd-cc8de250d0b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Dividir Datos para la tarea específica (NSP)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30781d13-79e8-4cd9-8f09-6d42b7716797",
   "metadata": {},
   "source": [
    "Ahora que hemos cargado los datos, debemos dividir el conjunto de datos para poder etiquetar las frases que siguen las unas a las otras.\n",
    "\n",
    "Esto se conoce como la tarea NSP (Next Sentence Prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba719223-baae-4631-9318-8bcefdfc152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From Maximus I learned self-government, and not to be led aside by anything; and cheerfulness in all circumstances, as well as in illness; and a just admixture in the moral character of sweetness and dignity, and to do what was set before me without complaining. I observed that everybody believed that he thought as he spoke, and that in all that he did he never had any bad intention; and he never showed amazement and surprise, and was never in a hurry, and never put off doing a thing, nor was perplexed nor dejected, nor did he ever laugh to disguise his vexation, nor, on the other hand, was he ever passionate or suspicious. He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved. I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man. He had also the art of being humorous in an agreeable way.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar frases de cada uno de los párrafos extraídos\n",
    "bag = [item for sentence in text for item in sentence.split('.') if item != '']\n",
    "# Tamaño de la bolsa de frases\n",
    "bag_size = len(bag)\n",
    "\n",
    "print(bag_size)\n",
    "text[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e822a2fe-1f32-4101-9f3d-b47d6c2c7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar ejemplo de bolsa de frases\n",
    "bag[14:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8278ed-14bf-40af-98f1-f4392d1b2dd8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Construir Dataset que espera el modelo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fa3c4-64d0-4801-8084-eae1a0b52db0",
   "metadata": {},
   "source": [
    "Ahora seleccionaremos 50/50 frases al azar que siguen unas de las otras y las marcaremos.\n",
    "\n",
    "Aquí, 0 representa la siguiente frases y 1 que no es la siguiente frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9586ea2c-96a4-4fe8-8f24-a450035be41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "# Seleccionar párrafo\n",
    "for paragraph in text:\n",
    "    # Separar frases en el párrafo\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph.split('.') if sentence != ''\n",
    "    ]\n",
    "    # Contar frases\n",
    "    num_sentences = len(sentences)\n",
    "    # Debe haber al menos una frase\n",
    "    if num_sentences > 1:\n",
    "        # Seleccionar índice al azar\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        # Lanzar moneda\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            # Anexar pares correspondientes\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            # Crear etiqueta de IsNextSentence\n",
    "            label.append(0)\n",
    "        else:\n",
    "            # De otra manera, seleccionar de la bolsa de frases\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            # this is NotNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            # Anexar parejas no correspondientes\n",
    "            sentence_b.append(bag[index])\n",
    "            # Crear etiqueta de NotNextSentence\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388158bc-abbd-4a4a-a254-6c4354178d0a",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de cómo quedó nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7719579-ba19-4494-a9a4-2e307090cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " He was accustomed to do acts of beneficence, and was ready to forgive, and was free from all falsehood; and he presented the appearance of a man who could not be diverted from right rather than of a man who had been improved\n",
      "---\n",
      " I observed, too, that no man could ever think that he was despised by Maximus, or ever venture to think himself a better man\n",
      "\n",
      "1\n",
      " Further, he was not fond of change nor unsteady, but he loved to stay in the same places, and to employ himself about the same things; and after his paroxysms of headache he came immediately fresh and vigorous to his usual occupations\n",
      "---\n",
      " Show him where his error is\n",
      "\n",
      "1\n",
      " Further, I owe it to the gods that I was not hurried into any offence against any of them, though I had a disposition which, if opportunity had offered, might have led me to do something of this kind; but, through their favour, there never was such a concurrence of circumstances as put me to the trial\n",
      "---\n",
      " For as every soul is unwillingly deprived of the truth, so also is it unwillingly deprived of the power of behaving to each man according to his deserts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    # Seleccionar etiqueta\n",
    "    print(label[i])\n",
    "    # Seleccionar primer par de frases\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    # Seleccionar segundo par de frases\n",
    "    print(sentence_b[i] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a653f-e1f9-4e20-b1d2-9c142d5e8a86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Tokenizar Frases</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198725da-f439-4001-bb13-c5bcf9f60358",
   "metadata": {},
   "source": [
    "Como siguiente paso, debemos tokenizar las frases de nuestro conjunto creado,teniendo en cuenta los argumentos del tokenizador creados para esta tarea (Observe como se pasan los textos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8841749b-f296-4bd7-ad41-264ab80f7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Máxima longitud de tokens -> 512\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt',max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765850-abf8-439f-b04c-54de3a48ba95",
   "metadata": {},
   "source": [
    "Como podemos observar, el output del tokenizador es u diccionario que contiene los items tokenizados y listo para pasar por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1179506a-3167-4f87-880c-739b6654a105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b632d577-f36c-4056-9d1b-36e73f75f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2002,  2001,  ...,     0,     0,     0],\n",
       "        [  101,  2582,  1010,  ...,     0,     0,     0],\n",
       "        [  101,  2582,  1010,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3459,  2185,  ...,     0,     0,     0],\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef29b27-17fc-445a-aa58-4c3998635173",
   "metadata": {},
   "source": [
    "Note que en el DataFrame los tipos de tokens cambian (son uno), para indicar que las frases son pares, y luego los ceros finales indican el padding hasta 52 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81936ad8-8e2a-44c2-bb59-19da8df8e663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    ...  505  506  507  508  509  510  511\n",
       "0      0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "1      0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "2      0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "3      0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "4      0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "312    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "313    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "314    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "315    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "316    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
       "\n",
       "[317 rows x 512 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',512)\n",
    "pd.DataFrame(inputs.token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681ea40-a62d-4317-860f-663d04c18623",
   "metadata": {},
   "source": [
    "Ahora debemos convertir las etiquetas en un tensor de pytorch para poder procesarlos después:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c63f47ff-bcc7-4b9e-aeb7-5a63f1bb370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas en tensor dentro del diccionario de los inputs\n",
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8f83658-6aef-4502-be08-3e0be76075d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 0, 1, 1, 1, 0, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo\n",
    "print(inputs.next_sentence_label[:10].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff262d7-2731-4fca-b0c3-0319b77da7a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Construir etiquetas para la tarea MLM (Masked Language Model)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd74ae5-17bc-4ee4-8f93-0917fefdec23",
   "metadata": {},
   "source": [
    "Ya tenemos listo el modelo para la tarea NSP.\n",
    "\n",
    "Ahora debemos preparar nuestros datos para la tarea de Masking.\n",
    "\n",
    "Esto es, quitar palabras al azar de las frases y tratar de recuperarlas con el modelo.\n",
    "\n",
    "Para este caso, como es un proceso de clasificación, los tokens serán nuestra etiqueta dentro del vocabulario del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92a56e42-6f89-4bd9-9b8a-62b19e161bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels para la tarea MLM\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93ef24a1-1cdb-40a7-b181-8d7a4d7b11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66d9705d-113a-45a3-884a-90b563fb799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear una matriz aleatoria de floats con dimensiones iguales al tensor input_ids\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# Crear arreglo de máscara (15% del tiempo) y quitar tokens especiales del proceso\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d215d4b8-c469-4c25-bb26-10eedaccab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "# Tomar los índices de valores True en cada vector\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "945b5210-8169-471d-b015-64f6a2918007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 6, 9, 12, 17, 22, 35, 36, 43, 53, 64],\n",
       " [11, 21, 32, 33, 34, 41, 44, 45, 57]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Índices seleccionados\n",
    "selection[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88d06026-c17e-4189-a5c5-3ec36cb29fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar índice especial para la máscara\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec4acfc5-30fd-4edb-8717-89b8c171844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dbf65cb-b825-44ad-8dfe-9cc7cf834026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2002,   103,  ...,     0,     0,     0],\n",
       "        [  101,  2582,  1010,  ...,     0,     0,     0],\n",
       "        [  101,   103,  1010,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3459,  2185,  ...,     0,     0,     0],\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor de inputs con máscara\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4c312-cf84-4152-91ff-094e74e17e7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Construir Dataset y DataLoader</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e0884-1872-43db-be92-638f17fc09b5",
   "metadata": {},
   "source": [
    "Para acelerar el proceso de entrenamiento y poder hacerlo por batches, creamos un dataset y un dataloader respectivamente para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0ff8b-2666-4655-82a3-71706a104eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        # Obtener codificación\n",
    "        self.encodings = encodings\n",
    "        # Obtener items\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    # Obtener longitud del dataset\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "099d0182-da98-41af-8b33-1d7429a92daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciar dataset\n",
    "dataset = OurDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b247f029-98e8-4813-9d9d-b7bd12effd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DataLoader (batches de 16)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bb7f9-083d-4c6a-8dd9-01890063603f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Fine-Tuning BERT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deea390-3d40-49b9-8b05-619f0b338c18",
   "metadata": {},
   "source": [
    "Ya que tenemos nuestros datos listos, ahora podemos entrenar el modelo y hacer nuestro fine-tuning.\n",
    "\n",
    "EL loop de training va como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "967913d9-811b-4107-941b-5c94e3ed1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/20 [00:00<?, ?it/s]/var/folders/d_/hfs18jf54371qfmf54zq289c0000gn/T/ipykernel_76545/541448751.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [15:22<00:00, 46.12s/it, loss=2.58]\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [15:06<00:00, 45.31s/it, loss=2.06]\n"
     ]
    }
   ],
   "source": [
    "# Barra de progreso\n",
    "from tqdm import tqdm\n",
    "# Cargar Optimizadores\n",
    "from torch.optim import Adam,AdamW\n",
    "# Otpimizador recoge información sobre los parámetro del modelo BERT\n",
    "optim = AdamW(model.parameters())\n",
    "\n",
    "# Si tienes GPU, debes modificar esta línea\n",
    "device='cpu'\n",
    "\n",
    "# Dos epochs\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # Inicializar gradiente (sin acumulación)\n",
    "        optim.zero_grad()\n",
    "        # Colocar batches de información en el dispositivo indicado\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # Red forward que usa NSP y MLM\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "        # Calcular pérdida\n",
    "        loss = outputs.loss\n",
    "        # Calcular gradiente\n",
    "        loss.backward()\n",
    "        # actualizar parámetros\n",
    "        optim.step()\n",
    "        # Mostrar información importante\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b0839e-6da1-41b8-8f51-7a39e12f4068",
   "metadata": {},
   "source": [
    "Observemos cómo la pérdida baja de un epoch a otro.\n",
    "\n",
    "También, note lo costoso comoputacionalmente que es el proceso, pero comparado con inicializar el modelo desde cero, es un costo que podemos aceptar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea060472-cd50-495f-b118-1df38a613b86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Fine-Tune para otras tareas (HuggingFace)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58064808-2d92-4172-9147-8cc06c12dcb9",
   "metadata": {},
   "source": [
    "Ahora exploremos tareas **Downstream**, es decir, utilicemos BERT para otra tarea que no sea NSP o MLM.\n",
    "\n",
    "En esta sección construiremos un clasificador multi-clase para análisis de sentimientos.\n",
    "\n",
    "Para este caso, utilizaremos un dataset de HuggingFace.\n",
    "\n",
    "Si quiere replicar este proceso tal cual como se indica en este ejemplo, deberá construir un dataset de HuggingFace.\n",
    "\n",
    "De otra manera, puede seguir el mismo proceso hecho con anterioridad (DataLoader) para crear los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f539bed1-6cb9-4219-ba5a-20a6e4efeec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc9a095e4b64377882a13d51c977cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55a2a0f3a114883989413f043a52b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/979 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset yelp_review_full/yelp_review_full (download: 187.06 MiB, generated: 496.94 MiB, post-processed: Unknown size, total: 684.00 MiB) to /Users/moury/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5f70c5ab940ed9c8e7f937be221b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yelp_review_full downloaded and prepared to /Users/moury/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669a98d9d7224e30afb114040f8b5ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# usaremos el dataset yelp_review_full\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd195a9-631c-4255-a524-7b844f4f8974",
   "metadata": {},
   "source": [
    "La filosofía de HuggingFace: *Make things simple and easy.*\n",
    "\n",
    "Es por eso que esta plataforma cuenta con un AutoTokenizador, que se encarga de tomar el tokenizador adecuado para el modelo especificado.\n",
    "\n",
    "Otra cosa interesante de los datasets de HF, es que permite el uso de la función `map` para procesar alto volúmenes de información en forma de batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88a278e7-0a36-4631-a0db-22d796132a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ccff2768704b359eadd7a9065ec382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9841413427fc4bd9a9d693617438c358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5a8a2-2835-4cee-b71b-dffd39866375",
   "metadata": {},
   "source": [
    "Como este conjunto es bastante grande, seleccionaremos sólo un conjunto de 1000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73680a07-e160-40d6-956c-b7368c2f52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e581646-24c7-4de5-9ccf-a025dc87edc2",
   "metadata": {},
   "source": [
    "También, usaremos AutoModelFor**Task**. Observe lo fácil que es construir el clasificador con un número de etiquetas especificado (5 en este caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8851eb26-af15-4ba9-9b2c-9812702d44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7247c-8cbf-464e-963d-f705a98ba3cd",
   "metadata": {},
   "source": [
    "Dentro de los argumentos de entrenamiento, podemos especificar, por ejemplo, la carpeta dónde quedará nuestro checkpoint, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29ff8dd3-3bbd-4f79-bb77-661a9309497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e12ac-6854-4126-a81f-a2808539231b",
   "metadata": {},
   "source": [
    "También podemos traer métricas de la clase dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b08bd1-2d8f-46cf-b57f-e42a3357d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82428b4-e819-408d-b8a7-956f6dcdffe8",
   "metadata": {},
   "source": [
    "Generamos las predicciones y calculamos el accuracy del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2839a09-95f7-4d4f-8d70-03e7a7c5557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50321ff2-0f3e-4f08-9092-ff63e5633b0b",
   "metadata": {},
   "source": [
    "Además podemos elegir la forma de evaluación del modelo, que en este caso hemos elegido como \"epoch\" (3 por defecto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2dda2d43-e247-4b3b-88bb-9ef0d0f158c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00ff2f-4d0a-45fc-adbc-54b024c9ef8d",
   "metadata": {},
   "source": [
    "Y ahora viene lo más fabuloso de HuggingFace:\n",
    "\n",
    "Su API Trainer para hacer los procesos más flexibles para investigación:\n",
    "\n",
    "Observe lo sencillo que es generar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25f8ba52-ae58-4b5e-8a5a-0b6250fd27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d6a8c-891a-41fe-bff9-043290cfa672",
   "metadata": {},
   "source": [
    "Y lo fácil que es entrenarlo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb6f1e-2b6c-4588-bfaf-c1f0d1a6346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moury/miniforge3/envs/numpy_test/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='289' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [289/375 11:31:20 < 3:27:09, 0.01 it/s, Epoch 2.30/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.219129</td>\n",
       "      <td>0.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.122104</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1cf5f-675c-4e69-9e15-a8033133d55d",
   "metadata": {},
   "source": [
    "Ahora bien, para una epoch y sin GPUs, el modelo tarda approx 2 horas/epoch. Mejor vaya por un tinto y vuelva más tarde.\n",
    "\n",
    "**Enhorabuena,** usted ha hecho su primer clasificador utilizando un modelo BERT.\n",
    "\n",
    "Llámelo BERT-5CR (BERT 5 Class Review)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b2a25f-49d2-46be-9c05-3d034503cd6b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Fine-Tune SentenceBert</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708830db-02c9-4de5-8871-f07584fe5937",
   "metadata": {},
   "source": [
    "También es posible hacer fine-tuning de modelos SentenceBert, como se indica a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccb7465-0b51-4fda-a980-733bddd03fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7430f778-1bd9-4f97-96a4-4d7855a68bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a0d132-b4e0-47c4-8196-e364650521b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab8fe86e24c4f928b51cba510f676c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/392k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sts_dataset_path = 'datasets/stsbenchmark.tsv.gz'\n",
    "\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b404468-4583-4367-a4b1-4cc82e4aebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "model_name = 'nli-distilroberta-base-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_stsbenchmark_continue_training-'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90151071-7806-40b6-87b5-0203f9c70ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:06:28 - Load pretrained SentenceTransformer: nli-distilroberta-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3587672cc3493394620bf037af69c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/736 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8bcb0bef524c34bd8de6a9c872096f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089ed6f36b0d4f9f83e91134db7dfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4841fdad26064c34ace73d83c47d3083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5959d19e78488da9379c26a79a87a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb84deb5b824e21bf3844878d20b1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb951fa1dddb4df48e945c6183fe4700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6821c60f07a54c78ba77d63c7de57881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74be6a9e60034af9aeef57a5516ad77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe844d9ad05494080f7b7af9dbfa608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55b9da0f6bc4c7a8405e6b8e6c51124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69145dfda9254d96a37e987f4e64d4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04aca1b550a48bcb773661dd7a57b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:07:04 - Use pytorch device: cpu\n",
      "2022-02-28 15:07:04 - Read STSbenchmark train dataset\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Convert the dataset to a DataLoader ready for training\n",
    "logging.info(\"Read STSbenchmark train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c52484-5af3-486f-8b45-0237288ae8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "        inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "\n",
    "        if row['split'] == 'dev':\n",
    "            dev_samples.append(inp_example)\n",
    "        elif row['split'] == 'test':\n",
    "            test_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54803829-53b3-4c5a-868a-395eec0eaa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_transformers.readers.InputExample.InputExample"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b35ac2-d23a-4607-a856-266cb2d5cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15a392d-3d68-4e23-9b3d-4e6f2bc064a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:12:12 - Read STSbenchmark dev dataset\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4eea682-ea21-4dca-9e68-51b8359c95fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:14:15 - Warmup-steps: 144\n"
     ]
    }
   ],
   "source": [
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245a508b-c077-4df7-9f2e-150fc43603f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e5caf5af58451ea29935a2770132b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d8de0843754e72ab88e7899f3b7402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:42:08 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2022-02-28 15:42:46 - Cosine-Similarity :\tPearson: 0.8866\tSpearman: 0.8866\n",
      "2022-02-28 15:42:46 - Manhattan-Distance:\tPearson: 0.8566\tSpearman: 0.8599\n",
      "2022-02-28 15:42:46 - Euclidean-Distance:\tPearson: 0.8578\tSpearman: 0.8616\n",
      "2022-02-28 15:42:46 - Dot-Product-Similarity:\tPearson: 0.8350\tSpearman: 0.8354\n",
      "2022-02-28 15:42:46 - Save model to output/training_stsbenchmark_continue_training-nli-distilroberta-base-v2-2022-02-28_15-04-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4585b37340a645949469a4781e1ed6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 15:57:40 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 1:\n",
      "2022-02-28 15:58:17 - Cosine-Similarity :\tPearson: 0.8903\tSpearman: 0.8902\n",
      "2022-02-28 15:58:17 - Manhattan-Distance:\tPearson: 0.8631\tSpearman: 0.8663\n",
      "2022-02-28 15:58:17 - Euclidean-Distance:\tPearson: 0.8647\tSpearman: 0.8685\n",
      "2022-02-28 15:58:17 - Dot-Product-Similarity:\tPearson: 0.8444\tSpearman: 0.8452\n",
      "2022-02-28 15:58:17 - Save model to output/training_stsbenchmark_continue_training-nli-distilroberta-base-v2-2022-02-28_15-04-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fd77e166c94358baeb149a0c9c7ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 16:13:52 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 2:\n",
      "2022-02-28 16:14:38 - Cosine-Similarity :\tPearson: 0.8890\tSpearman: 0.8897\n",
      "2022-02-28 16:14:38 - Manhattan-Distance:\tPearson: 0.8718\tSpearman: 0.8747\n",
      "2022-02-28 16:14:38 - Euclidean-Distance:\tPearson: 0.8736\tSpearman: 0.8772\n",
      "2022-02-28 16:14:38 - Dot-Product-Similarity:\tPearson: 0.8527\tSpearman: 0.8530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f10794d0bd48689457151894405657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 16:29:25 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 3:\n",
      "2022-02-28 16:30:05 - Cosine-Similarity :\tPearson: 0.8894\tSpearman: 0.8896\n",
      "2022-02-28 16:30:05 - Manhattan-Distance:\tPearson: 0.8712\tSpearman: 0.8751\n",
      "2022-02-28 16:30:05 - Euclidean-Distance:\tPearson: 0.8727\tSpearman: 0.8774\n",
      "2022-02-28 16:30:05 - Dot-Product-Similarity:\tPearson: 0.8536\tSpearman: 0.8540\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7664848-796d-454f-b04c-c872c6b7a283",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Pytorch Lightning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bea5c4-192b-4d62-a819-f1906ffc9768",
   "metadata": {},
   "source": [
    "Finalmente, si desea hacer modelos en muchos menos pasos, con autoidentificación de dipositivos disponibles, le presentamos **Pytorch Lightning**, la forma más fácil de hacer modelos en el tiempo actual sin sufrir en el intento en Pytorch.\n",
    "\n",
    "El paradigma de PL es que uno sólo debe sobreescribir las clases que se quieren configurar. El resto lo maneja por debajo PL.\n",
    "\n",
    "**¡Bienvenido a la nueva era!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aee3ec-3cf9-4239-8e2b-32a8b30a980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam,AdamW\n",
    "\n",
    "class Clasificador_BERT(pl.LightningModule):\n",
    "    def __init__(self,dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('hiiamsid/sentence_similarity_spanish_es')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.loss = F.cross_entropy\n",
    "        \n",
    "    def forward(self,input_id,mask):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        _, pooled_output = self.bert(input_ids = input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x_id,x,y = batch\n",
    "        # USE MODEL\n",
    "        _,z = self.bert(input_ids = x['input_ids'].squeeze(1),attention_mask = x['attention_mask'],return_dict=False)\n",
    "        z   = self.dropout(z)\n",
    "        z   = self.linear(z)\n",
    "        output = self.relu(z)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss,prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-6)\n",
    "        return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
