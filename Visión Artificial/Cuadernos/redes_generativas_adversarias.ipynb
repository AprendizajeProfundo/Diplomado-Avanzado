{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Visión por Computadora</center></span>\n",
    "## <span style=\"color:red\"><center>Redes Generativas Adversarias</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferencistas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "- Daniel  Montenegro, Msc, dextronomo@gmail.com \n",
    "- Oleg Jarma, Estadístico, ojarmam@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maria del Pilar Montenegro, pmontenegro88@gmail.com \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nayibe Yesenia Arias, naariasc@unal.edu.co\n",
    "- Venus Celeste Puertas, vpuertasg@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una parte importante de modelos de Aprendizaje automatizado son, como los vamos a llamar ahora, \"modelos discriminadores\", siendo capaces de diferenciar sobre diferentes tipos de datos. Entre estos están los modelos para las tareas de clasificación y detección.\n",
    "\n",
    "Pero hay otro tipo de modelos cuya intención no es aprender de los datos para hacer inferencia sobre estos, sino aprender para generar nuevos datos. Estos son los \"modelos generadores\".\n",
    "\n",
    "Vamos a charlar un poco del contexto de ambos tipos de modelos, junto con un una arquitectura que mezcla ambas clases de modelos para mejorar su rendimiento: Redes Generativas Adversarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Discriminación y generación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos una base de datos de fotos de tamaño 32x32, y queremos detectar si en estas hay un perro o un gato con base en las características que encontramos. Para hcer esto, definimos un modelo con:\n",
    "\n",
    "- Etiquetas: $Y=y$\n",
    "- Características: $X=\\{x_1, x_2, \\dots, x_n \\}$\n",
    "\n",
    "ahora, podemos pensar en cómo los modelos discriminadores y generadores utilizan estas variables para aprender y obtener resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Modelos discriminatorios</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo discriminador es esencialmente el modelo de la probabilidad de las etiquetas o \"variable respuesta\" $Y$, dadas las características o \"variables de observación\" $X$. Al final, queremos obtener las probabilidades de los casos de $P(Y|X=x)$. En resumidas cuentas, el modelo recibe las características y entrega las probabilidades de cada etiqueta.\n",
    "\n",
    "En nuestro ejemplo, con base en las características de la foto que le demos al modelo, este va a darnos dos probabilidades, la probabilidad de sea gato y que sea perro. Luego obtenemos el valor máximo de estas probabilidades para tener la \"predicción final\".\n",
    "\n",
    "Como se dijo con anterioridad, la mayoría de modelos enseñados tradicionalmente forman parte de esta categoría: Regresiones, Máquinas de soporte vectorial, Perceptrones e incluso las redes CNN con un componente completamente conectado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Modelos generadores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo generador hace las cosas un poco diferente, aunque hay varias formas de verlo:\n",
    "\n",
    "En la primera forma, el modelo generador es el modelo de la probabilidad de las variables de observación $X$, dada la variable respuesta $Y$. Así que se buscan las probabilidades de todos los casos $P(X|Y = y)$. \n",
    "\n",
    "En nuestro ejemplo, con base en la etiqueta que le demos, como \"perro\", el modelo va a generar las probabilidades de todas las posibles imágenes que pueden hacerse. en este caso $256^{32 \\times 32}$. Luego se obtiene aquella imagen con la mayor probabilidad, o la que el modelo cree que es la que mayor tiene que ver con la etiqueta \"perro\".\n",
    "\n",
    "Aunque esta no es la única forma de verlo. También se han planteado los modelos generadores como los modelos de las probabilidades conjuntas de $P(X,Y)$. Diciendo, de alguna forma, que no estamos seguros de lo que queremos, así que busquemos las probabilidades de todas las posibles combinaciones de características y etiquetas.\n",
    "\n",
    "En el último caso de nuestro ejemplo, Modelaremos todas estas combinaciones, las cuales son $256^{32 \\times 32}*2$, y para buscar aquella imagen que el modelo piense que es la más cercana a ser un \"perro\", se busca el máximo de las probabilidades de $P(X, Y=\\text{perro})$.\n",
    "\n",
    "Esto no significa que estas dos definiciones sean completamente separadas. Sabemos que las probabilidades conjuntos pueden encontrarse a partír de las condicionales\n",
    "\n",
    "\\begin{align}\n",
    "    P(X,Y)=P(X|Y)P(Y)\n",
    "\\end{align}\n",
    "\n",
    "Así que, si podemos modelar $P(Y)$, podemos pasar de una definición a otra.\n",
    "\n",
    "\n",
    "De hecho ya hemos visto un ejemplo de modelos generadores con los [Autoencoders](../../Autocodificadores/Cuadernos/ae_Example_Dense_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Redes Generativas Adversarias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hablemos de Poker\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/poker.gif\" width=\"400\" height=\"300\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Indiscutiblemente, la parte más interesante de este pseudodeporte es la parte de los \"juegos mentales\". El tener una mala mano, pero convencer que es buena, ganando a pesar de no tener nada. O poder pescar a quienes están mintiendo, ya bien sea un pequeño tick o una corazonada. Y es incluso más emocionante cuando se esta uno contra uno, en una situación de ADVERSARIOS.\n",
    "\n",
    "El nombre que se le da a esta arquitectura no es por nada. De hecho, se toma mucho la idea del \"juego\" y la competitividad(la cual ha impulsado tanto el desarrollo de la visión aritifical), pero esta vez no será por parte de los desarrolladores, las mismas redes van a competir entre sí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las Redes Generativas Adversarias(Generative Adversarial Networks o GANs como vamos a llamarlas), tienen la diferencia más importante en el entrenamiento de dos redes que no están conectadas directamente y que nisiquiera tienen la misma tarea.\n",
    "\n",
    "Estas dos redes van a ser:\n",
    "\n",
    "- Red generadora: Crea imágenes a partír de datos aleatorios. Aprende a hacerlas mejor con cada intervención\n",
    "- Red discriminadora: Busca decidir qué imagenes son \"reales\" y cuáles fueron creadas por la red generadora. Aprende a detallar más las diferencias entre los dos tipos de datos.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/gan1.png\" width=\"900\" height=\"500\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/gan2.png\" width=\"900\" height=\"500\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un poco del algoritmo de las GANs:\n",
    "\n",
    "En cada iteración sucede lo siguiente:\n",
    "\n",
    "- Entrenamiento del discriminador:\n",
    "    - Se toma un ejemplo real $x$ del dataset de entrenamiento\n",
    "    - Se toma un vector de \"ruido aleatorio\" $z$ y se crea un ejemplo falso $x^*$ usando el generador\n",
    "    - El discriminador clasifica $x$ y $x^*$ como \"falso\" o \"verdadero\"\n",
    "    - Se computa el error de las clasifcaciones y hacemos backpropagation sobre el discriminador, buscando **minimizar** el error de clasificación\n",
    "\n",
    "- Entrenamiento del generador:\n",
    "    -  Se toma un vector de \"ruido aleatorio\" $z$ y se crea un ejemplo falso $x^*$ usando el generador\n",
    "    - El discriminador clasifica $x^*$ como \"falso\" o \"verdadero\"\n",
    "    - Se computa el error de la clasifcación y hacemos backpropagation sobre el generador, buscando **maximizar** el error de clasificación del discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">El entrenamiento de una GAN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una forma más gráfica\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/GAN_training.png\" width=\"950\" height=\"600\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Cosas a tomar en cuenta de este proceso:\n",
    "\n",
    "- Los dos proceso de entrenamiento suceden **simultaneamente**. El entrenamiento de ambas redes está muy conectado\n",
    "- La red generadora nunca recibe información por parte de la base de datos. Empieza verdaderamente desde 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la naturaleza de este entrenamiento, es lógico preguntarse: ¿En qué momento suponemos que el entrenamiento está completo, si tenemos dos modelos aprendiendo y mejorando? como hemos dicho, estos dos modelos tienen una relación competitiva y, en forma resumida, estamos del bando del generador. Nuestro \"estado de victoria\" o \"equilibrio\", es cuando el generador sea tan bueno que la información que crea sea indiferente a la real, obligando al discriminador a, en el mejor de los casos, hacer una elección del 50/50. Es en este punto que, primero, el discriminador ya no puede hacer nada para mejorar si capacidad y, segundo, el generador ya no gana nada de más iteraciones. Es en este punto en el que decimos que ha convergido. Este estado de equilibrio es puramente teórico, así que se necesitan otras formas de calcular qué tan bueno es el desempeño de la red. cosa que se verá más adelante "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Increibles aplicaciones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las GANs son consideradas por muchos como unas de las ideas más interesantes de los últimos años, y se puede en sus aplicaciones. Varios de los trabajos hechos con esta arquitectura son tanto de los más innovadores como los más publicitados. Razón por la cual es buena idea repasar las posibilidades que tienen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">CycleGAN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual forma que podemos traducir un texto de un idioma a otro, también podemos \"traducir\" una imagen de un dominio a otro. ¿Qué significa esto?\n",
    "\n",
    "Imaginemos, si podemos, que tenemos una de las hermosas pinturas de Jean Claude Monet.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/water-lilies.jpg\" width=\"1000\" height=\"650\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Es inmediato el observar y apreciar la belleza de esta, pero a veces nos entra la curiosidad: ¿Qué estaba viendo él en la vida real para inspirarse? o ¿Cuál sería la interpretación de otro artista? Estos son los dominios que hablamos, pasamos del dominio \"Monet\" al dominio \"Realidad\"\n",
    "\n",
    "Esta es la idea detrás de los CycleGAN\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cyclegan-monet.png\" width=\"800\" height=\"350\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Los dominios no se reducen únicamente a diferentes artistas, los límites son pocos respecto a estos.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cyclegan-horse.png\" width=\"800\" height=\"350\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo logran esto? Plantearon dos pequeños extras en la red GAN \"tradicional\".\n",
    "\n",
    "- En lugar de tener \"parejas ordenadas\" $\\{x_i, y_i \\}$, cada uno de un respectivo dominio. Se toman los datasets como un \"todo\", permitiendo muestras más grandes, y logrando que se entienda más la idea general de cada dominio\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/paired_unpaired.png\" width=\"450\" height=\"275\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "- Para observar la convergencia de las redes se hace un \"ciclo\" de la imagen real, a la versión transformada, y de nuevo al dominio original. Se hace una comparación entre la original y la versión \"reconstruida\", y con esto observamos la convergencia.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/reconstruction.png\" width=\"450\" height=\"275\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Más del diseño de este puede verse en su [página oficial](https://junyanz.github.io/CycleGAN/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">StyleGAN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los inicios del desarrollo de las GANs y la generación de nuevo contenido visual, los inconvenientes principales eran la falta de detalle que tenían las imágenes y el reducido control que tendrían las personas sobre el tipo que fotos que quieren recibir. Esto signfica que, si le pedíamos una foto de un rostro a una de estas redes, el rostro no se vería de muy buena calidad, y tendríamos que conformarnos con la foto que haga, no podríamos decirle que haga una foto de un hombre con pelo corto y barba.\n",
    "\n",
    "Nuestros viejos amigos de Nvidia desarrollaron \"StyleGAN\" donde hacen varias cosas nuevas en el proceso tradicional, cosas pequeñas como normalizar datos, trabajar distintos tamaños etc...\n",
    "\n",
    "El cambio más grande fue el tomar a las imágenes como \"grupos\" de diferentes estilos. En el caso de los rostros los estilo pueden ser cosas como: forma del rostro, color del cabello, ojos, posición y esquema de los colores. Para definir estos estilos, se aplica una red de \"mapeo de características\", cuya salida entra al GAN principal junto con el vector aleatorio de ruido. Al final, el usuario sería capaz de cambiar los estilos de manera independiente.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/face_generator.gif\" width=\"650\" height=\"350\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Programación básica de una GAN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos con un proyecto sencillo para comprender la estructura básica de un código de GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a35811627f2d849a94a681c597b35b034065b47c984a0e4ef87a04e993e3cd2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
